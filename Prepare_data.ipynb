{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:49:57.070658Z",
     "iopub.status.busy": "2023-03-01T12:49:57.070266Z",
     "iopub.status.idle": "2023-03-01T12:49:57.221945Z",
     "shell.execute_reply": "2023-03-01T12:49:57.221107Z",
     "shell.execute_reply.started": "2023-03-01T12:49:57.070631Z"
    },
    "id": "WP5xSLHI-jKh"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:52:48.998402Z",
     "iopub.status.busy": "2023-03-01T12:52:48.998065Z",
     "iopub.status.idle": "2023-03-01T12:52:52.328848Z",
     "shell.execute_reply": "2023-03-01T12:52:52.327934Z",
     "shell.execute_reply.started": "2023-03-01T12:52:48.998377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.5.1)\n",
      "Collecting gdown\n",
      "  Downloading gdown-4.6.4-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.7.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.14.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.64.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Installing collected packages: gdown\n",
      "  Attempting uninstall: gdown\n",
      "    Found existing installation: gdown 4.5.1\n",
      "    Uninstalling gdown-4.5.1:\n",
      "      Successfully uninstalled gdown-4.5.1\n",
      "Successfully installed gdown-4.6.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U --no-cache-dir gdown --pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the project data\n",
    "> i.e. task2_data\n",
    ">\n",
    "> I manually extracted the zip folder into my working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:56:37.240674Z",
     "iopub.status.busy": "2023-03-01T12:56:37.240082Z",
     "iopub.status.idle": "2023-03-01T12:56:40.676338Z",
     "shell.execute_reply": "2023-03-01T12:56:40.675049Z",
     "shell.execute_reply.started": "2023-03-01T12:56:37.240627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1iU0qE7sM_AvdQnh0emkbcwwh2d3pE5TG\n",
      "To: /notebooks/task2_data.zip\n",
      "100%|█████████████████████████████████████████| 201M/201M [00:01<00:00, 109MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id '1iU0qE7sM_AvdQnh0emkbcwwh2d3pE5TG'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to create the training data which consists of images and their annotations\n",
    "\n",
    "\n",
    "> The `training` folder is said within my current working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T13:10:02.392290Z",
     "iopub.status.busy": "2023-03-01T13:10:02.391895Z",
     "iopub.status.idle": "2023-03-01T13:10:02.404598Z",
     "shell.execute_reply": "2023-03-01T13:10:02.403503Z",
     "shell.execute_reply.started": "2023-03-01T13:10:02.392260Z"
    }
   },
   "outputs": [],
   "source": [
    "## prepare data for yolo model\n",
    "def prep_data(csv_file, images):\n",
    "    \n",
    "    names = { 1:'longitudinal_high',2:'longitudinal_low',3:'longitudinal_medium', \n",
    "           4:'grass', 5:'patch_high', 6:'manhole_high', 7:'transverse_high',\n",
    "           8:'transverse_low', 9:'transverse_medium', 10:'diag_high', \n",
    "           11:'diag_low', 12:'diag_medium', 13:'alligator_high', \n",
    "           14:'alligator_low', 15:'alligator_medium',  16:'block_low', \n",
    "           17:'block_high', 18:'block_medium'}\n",
    "\n",
    "\n",
    "    dst_imgs_path = 'training/images'\n",
    "    dst_lbls_path = 'training/labels'\n",
    "    \n",
    "    if not os.path.isdir('training/images'):\n",
    "        os.makedirs(dst_imgs_path)\n",
    "        os.makedirs(dst_lbls_path)\n",
    "        \n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    img_ids = df['img_name'].unique()\n",
    "    \n",
    "    for img in img_ids:\n",
    "        df_cur = df[df['img_name'] == img]\n",
    "        full_img_path = os.path.join(images,img)\n",
    "        frame = cv2.imread(full_img_path)\n",
    "        height,width,chan = frame.shape\n",
    "        for data in df_cur.values.tolist():\n",
    "            cimg,x1,y1,x2,y2 = data[0:-2]\n",
    "            ccolor = data[-2] + '_' + data[-1]\n",
    "            value = [i for i in names if names[i]==ccolor]\n",
    "            cls = value[0]\n",
    "            dw = 1. / width\n",
    "            dh = 1. / height\n",
    "            x = (x1 + x2) / 2.0\n",
    "            y = (y1 + y2) / 2.0\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            x = x * dw\n",
    "            w = w * dw\n",
    "            y = y * dh\n",
    "            h = h * dh\n",
    "\n",
    "            file_path_img = os.path.join(dst_lbls_path, img)\n",
    "            filename, file_extension = os.path.splitext(file_path_img)\n",
    "        # print (filename,file_extension)\n",
    "            with open(file_path_img.replace(file_extension,'.txt'), 'a+') as f:\n",
    "                f.write(' '.join([str(int(cls)), str(float(x)), str(float(y)), str(float(w)), str(float(h))]))\n",
    "                f.write('\\n')\n",
    "\n",
    "        shutil.copy(full_img_path,os.path.join(dst_imgs_path, img))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converts annotations into yolo format\n",
    "## creates new folder - training data\n",
    "csv_file = 'task2_data/annotations.csv'\n",
    "images = 'task2_data/images'\n",
    "\n",
    "# data = prep_data(csv_file, images)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfgsaxsgLqOO"
   },
   "source": [
    "## Split the Dataset into Training and Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T13:12:57.793472Z",
     "iopub.status.busy": "2023-03-01T13:12:57.792412Z",
     "iopub.status.idle": "2023-03-01T13:12:57.806084Z",
     "shell.execute_reply": "2023-03-01T13:12:57.805331Z",
     "shell.execute_reply.started": "2023-03-01T13:12:57.793429Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset(path_to_dataset, split_ratio=0.8):\n",
    "    \n",
    "    # Set the path to the training folder and the names of the train and val folders\n",
    "    training_folder = path_to_dataset\n",
    "    train_folder = 'train_data'\n",
    "    val_folder = 'val_data'\n",
    "\n",
    "    # Set the train/val split ratio\n",
    "    split_ratio = split_ratio\n",
    "\n",
    "    # Create the train and val folders if they don't exist\n",
    "    if not os.path.exists(train_folder):\n",
    "        os.makedirs(os.path.join(train_folder, 'images'))\n",
    "        os.makedirs(os.path.join(train_folder, 'labels'))\n",
    "\n",
    "    if not os.path.exists(val_folder):\n",
    "        os.makedirs(os.path.join(val_folder, 'images'))\n",
    "        os.makedirs(os.path.join(val_folder, 'labels'))\n",
    "\n",
    "    # Get the list of image and label files in the training folder\n",
    "    image_files = os.listdir(os.path.join(training_folder, 'images'))\n",
    "    label_files = os.listdir(os.path.join(training_folder, 'labels'))\n",
    "\n",
    "    # Get the number of files to put in the train and val sets\n",
    "    num_files = len(image_files)\n",
    "    num_train_files = int(num_files * split_ratio)\n",
    "    num_val_files = num_files - num_train_files\n",
    "\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    for i in range(num_train_files):\n",
    "        image_file = image_files[i]\n",
    "        label_file = image_file[:-4] + '.txt'\n",
    "        shutil.copy(os.path.join(training_folder, 'images', image_file),\n",
    "                    os.path.join(train_folder, 'images', image_file))\n",
    "        shutil.copy(os.path.join(training_folder, 'labels', label_file),\n",
    "                    os.path.join(train_folder, 'labels', label_file))\n",
    "\n",
    "    # Copy the remaining images and labels to the val set\n",
    "    for i in range(num_train_files, num_files):\n",
    "        image_file = image_files[i]\n",
    "        label_file = image_file[:-4] + '.txt'\n",
    "        shutil.copy(os.path.join(training_folder, 'images', image_file),\n",
    "                    os.path.join(val_folder, 'images', image_file))\n",
    "        shutil.copy(os.path.join(training_folder, 'labels', label_file),\n",
    "                    os.path.join(val_folder, 'labels', label_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T08:13:29.593797Z",
     "iopub.status.busy": "2023-02-24T08:13:29.593445Z",
     "iopub.status.idle": "2023-02-24T08:13:29.631989Z",
     "shell.execute_reply": "2023-02-24T08:13:29.631230Z",
     "shell.execute_reply.started": "2023-02-24T08:13:29.593762Z"
    },
    "id": "FZ6HRXrzSvHn"
   },
   "outputs": [],
   "source": [
    "# Path to the main data to be splitted into train and validation\n",
    "path_to_dataset = 'training'\n",
    "split_dataset(path_to_dataset=path_to_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDxbos3CrC2R"
   },
   "source": [
    "### Test whether our split dataset function is working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-03-01T13:11:15.872212Z",
     "iopub.status.busy": "2023-03-01T13:11:15.870977Z",
     "iopub.status.idle": "2023-03-01T13:11:15.901947Z",
     "shell.execute_reply": "2023-03-01T13:11:15.901073Z",
     "shell.execute_reply.started": "2023-03-01T13:11:15.872180Z"
    },
    "id": "Gsh1d6BYrN_W",
    "outputId": "2c47be9f-5094-4366-a761-17b56dd07828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the train_data:  160\n",
      "Number of labels in the train_data:  160\n",
      "Number of images in the val_data:  41\n",
      "Number of labels in the val_data:  41\n"
     ]
    }
   ],
   "source": [
    "train_data = os.listdir(os.path.join('train_data', 'images'))\n",
    "train_lbl = os.listdir(os.path.join('train_data', 'labels'))\n",
    "\n",
    "print('Number of images in the train_data: ', len(train_data))\n",
    "print('Number of labels in the train_data: ', len(train_lbl))\n",
    "\n",
    "val_data = os.listdir(os.path.join('val_data', 'images'))\n",
    "val_lbl = os.listdir(os.path.join('val_data', 'labels'))\n",
    "\n",
    "print('Number of images in the val_data: ', len(val_data))\n",
    "print('Number of labels in the val_data: ', len(val_lbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T13:25:01.267023Z",
     "iopub.status.busy": "2023-03-01T13:25:01.266312Z",
     "iopub.status.idle": "2023-03-01T13:25:06.294698Z",
     "shell.execute_reply": "2023-03-01T13:25:06.293546Z",
     "shell.execute_reply.started": "2023-03-01T13:25:01.266995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=11iKT_JlR5OPhLLdMtP1wkxNQ-fz6_who\n",
      "To: /notebooks/test.zip\n",
      "100%|██████████████████████████████████████| 99.8M/99.8M [00:01<00:00, 77.6MB/s]\n",
      "Archive:  test.zip\n",
      "  inflating: ./images/4 (30).JPG     \n",
      "  inflating: ./images/2 (15).JPG     \n",
      "  inflating: ./images/3 (3).JPG      \n",
      "  inflating: ./images/4 (1).JPG      \n",
      "  inflating: ./images/3 (16).JPG     \n",
      "  inflating: ./images/2 (2).JPG      \n",
      "  inflating: ./images/4 (32).JPG     \n",
      "  inflating: ./images/2 (11).JPG     \n",
      "  inflating: ./images/3 (6).JPG      \n",
      "  inflating: ./images/4 (16).JPG     \n",
      "  inflating: ./images/2 (9).JPG      \n",
      "  inflating: ./images/4 (12).JPG     \n",
      "  inflating: ./images/3 (2).JPG      \n",
      "  inflating: ./images/4 (35).JPG     \n",
      "  inflating: ./images/4 (21).JPG     \n",
      "  inflating: ./images/4 (25).JPG     \n",
      "  inflating: ./images/4 (20).JPG     \n",
      "  inflating: ./images/4 (19).JPG     \n",
      "  inflating: ./images/2 (6).JPG      \n",
      "  inflating: ./images/4 (31).JPG     \n",
      "  inflating: ./images/4 (2).JPG      \n",
      "  inflating: ./images/4 (3).JPG      \n",
      "  inflating: ./images/3 (10).JPG     \n",
      "  inflating: ./images/4 (36).JPG     \n",
      "  inflating: ./images/4 (28).JPG     \n",
      "  inflating: ./images/3 (9).JPG      \n",
      "  inflating: ./images/2 (8).JPG      \n",
      "  inflating: ./images/2 (17).JPG     \n",
      "  inflating: ./images/4 (24).JPG     \n",
      "  inflating: ./images/4 (23).JPG     \n",
      "  inflating: ./images/4 (15).JPG     \n",
      "  inflating: ./images/4 (29).JPG     \n",
      "  inflating: ./images/4 (17).JPG     \n",
      "  inflating: ./images/4 (22).JPG     \n",
      "  inflating: ./images/2 (7).JPG      \n",
      "  inflating: ./images/4 (34).JPG     \n",
      "  inflating: ./images/4 (10).JPG     \n",
      "  inflating: ./images/4 (18).JPG     \n",
      "  inflating: ./images/3 (1).JPG      \n",
      "  inflating: ./images/2 (14).JPG     \n",
      "  inflating: ./images/3 (13).JPG     \n",
      "  inflating: ./images/3 (17).JPG     \n",
      "  inflating: ./images/4 (33).JPG     \n",
      "  inflating: ./images/4 (37).JPG     \n",
      "  inflating: ./images/3 (14).JPG     \n",
      "  inflating: ./images/4 (14).JPG     \n",
      "  inflating: ./images/2 (10).JPG     \n",
      "  inflating: ./images/4 (26).JPG     \n",
      "  inflating: ./images/4 (13).JPG     \n",
      "  inflating: ./images/3 (5).JPG      \n",
      "  inflating: ./images/2 (5).JPG      \n",
      "  inflating: ./images/2 (3).JPG      \n",
      "  inflating: ./images/3 (4).JPG      \n",
      "  inflating: ./images/4 (27).JPG     \n",
      "  inflating: ./images/3 (8).JPG      \n",
      "  inflating: ./images/3 (15).JPG     \n",
      "  inflating: ./images/3 (7).JPG      \n",
      "  inflating: ./images/3 (11).JPG     \n",
      "  inflating: ./images/3 (12).JPG     \n",
      "  inflating: ./images/2 (1).JPG      \n",
      "  inflating: ./images/2 (16).JPG     \n",
      "  inflating: ./images/2 (4).JPG      \n",
      "  inflating: ./images/4 (4).JPG      \n",
      "  inflating: ./images/4 (38).JPG     \n",
      "  inflating: ./images/2 (12).JPG     \n",
      "  inflating: ./images/4 (58).JPG     \n",
      "  inflating: ./images/4 (48).JPG     \n",
      "  inflating: ./images/4 (65).JPG     \n",
      "  inflating: ./images/4 (11).JPG     \n",
      "  inflating: ./images/4 (53).JPG     \n",
      "  inflating: ./images/4 (41).JPG     \n",
      "  inflating: ./images/4 (62).JPG     \n",
      "  inflating: ./images/4 (5).JPG      \n",
      "  inflating: ./images/4 (67).JPG     \n",
      "  inflating: ./images/4 (43).JPG     \n",
      "  inflating: ./images/4 (66).JPG     \n",
      "  inflating: ./images/4 (69).JPG     \n",
      "  inflating: ./images/4 (57).JPG     \n",
      "  inflating: ./images/4 (61).JPG     \n",
      "  inflating: ./images/4 (49).JPG     \n",
      "  inflating: ./images/4 (50).JPG     \n",
      "  inflating: ./images/2 (13).JPG     \n",
      "  inflating: ./images/4 (9).JPG      \n",
      "  inflating: ./images/4 (47).JPG     \n",
      "  inflating: ./images/4 (8).JPG      \n",
      "  inflating: ./images/4 (40).JPG     \n",
      "  inflating: ./images/4 (70).JPG     \n",
      "  inflating: ./images/4 (59).JPG     \n",
      "  inflating: ./images/4 (56).JPG     \n",
      "  inflating: ./images/4 (44).JPG     \n",
      "  inflating: ./images/4 (54).JPG     \n",
      "  inflating: ./images/4 (6).JPG      \n",
      "  inflating: ./images/4 (51).JPG     \n",
      "  inflating: ./images/4 (63).JPG     \n",
      "  inflating: ./images/4 (64).JPG     \n",
      "  inflating: ./images/4 (39).JPG     \n",
      "  inflating: ./images/4 (60).JPG     \n",
      "  inflating: ./images/4 (42).JPG     \n",
      "  inflating: ./images/4 (55).JPG     \n",
      "  inflating: ./images/4 (46).JPG     \n",
      "  inflating: ./images/4 (7).JPG      \n",
      "  inflating: ./images/4 (52).JPG     \n",
      "  inflating: ./images/4 (68).JPG     \n",
      "  inflating: ./images/4 (45).JPG     \n"
     ]
    }
   ],
   "source": [
    "## Download test data\n",
    "!gdown --id '11iKT_JlR5OPhLLdMtP1wkxNQ-fz6_who'\n",
    "!unzip 'test.zip' -d './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T13:26:15.402547Z",
     "iopub.status.busy": "2023-03-01T13:26:15.401931Z",
     "iopub.status.idle": "2023-03-01T13:26:15.423311Z",
     "shell.execute_reply": "2023-03-01T13:26:15.421938Z",
     "shell.execute_reply.started": "2023-03-01T13:26:15.402516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/notebooks/test/images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone 'https://github.com/UM-Titan/DSPS23.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r '/notebooks/DSPS23/requirements.txt'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
